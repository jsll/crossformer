{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "534daf7f-4b6b-4357-9a38-9117f72ce9b4",
   "metadata": {},
   "source": [
    "# Step 1: Minimal CrossFormer Inference Example\n",
    "\n",
    "This Colab demonstrates how to load a pre-trained / finetuned CrossFormer checkpoint, run inference for a single-arm and bimanual manipulation system, and compare the outputs to the true actions.\n",
    "\n",
    "First, let's start with a minimal example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5312c8-fa0e-4f0e-91a6-0c4e82153f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import jax\n",
    "import tensorflow_datasets as tfds\n",
    "import tqdm\n",
    "import mediapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d34283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from crossformer.model.crossformer_model import CrossFormerModel\n",
    "\n",
    "model = CrossFormerModel.load_pretrained(\"hf://rail-berkeley/crossformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4b836-80ca-4210-b82c-b1b9a4de7df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import certifi\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "os.environ['CURL_CA_BUNDLE'] = certifi.where()\n",
    "\n",
    "\n",
    "# create RLDS dataset builder\n",
    "builder = tfds.builder_from_directory(\n",
    "    builder_dir=\"gs://gresearch/robotics/bridge/0.1.0/\"\n",
    ")\n",
    "ds = builder.as_dataset(split=\"train[:1]\")\n",
    "\n",
    "# sample episode and resize to 224x224 (default third-person cam resolution)\n",
    "episode = next(iter(ds))\n",
    "steps = list(episode[\"steps\"])\n",
    "images = [\n",
    "    cv2.resize(np.array(step[\"observation\"][\"image\"]), (224, 224)) for step in steps\n",
    "]\n",
    "\n",
    "# extract goal image and language instruction\n",
    "goal_image = images[-1]\n",
    "language_instruction = (\n",
    "    steps[0][\"observation\"][\"natural_language_instruction\"].numpy().decode()\n",
    ")\n",
    "\n",
    "# visualize episode\n",
    "print(f\"Instruction: {language_instruction}\")\n",
    "#mediapy.show_video(images, fps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafaf07b-88fa-4818-990d-31dc366a44ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 1\n",
    "\n",
    "# create task dictionary\n",
    "task = model.create_tasks(\n",
    "    goals={\"image_primary\": goal_image[None]}\n",
    ")  # for goal-conditioned\n",
    "task = model.create_tasks(texts=[language_instruction])  # for language conditioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0e7ad4-a7a4-460a-a09e-722f03cefec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in tqdm.trange(len(images) - (WINDOW_SIZE - 1)):\n",
    "input_images = np.stack(images[0 : 0 + WINDOW_SIZE])[None]\n",
    "observation = {\n",
    "    \"image_primary\": input_images,\n",
    "    \"timestep_pad_mask\": np.full((1, input_images.shape[1]), True, dtype=bool),\n",
    "}\n",
    "\n",
    "rollout, token_types = model.analyze_attention(observation, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d4ba89-6977-4b7f-95d6-76a1d2c20b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crossformer.utils import visualization_utils\n",
    "#import importlib\n",
    "#importlib.reload(visualization_utils)\n",
    "fig = visualization_utils.plot_readout_attention(rollout, token_types, \"readout_nav\", observation, observation_type=\"_primary\", observation_image=observation[\"image_primary\"][0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
